nohup: ignoring input
Reading lines...
Transfer numbers...
Indexing words...
Indexed 23 words in output
Number of training data 21162
Number of testind data 1000
Some weights of the model checkpoint at /root/autodl-tmp/MWP-BERT were not used when initializing EnhanceBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing EnhanceBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing EnhanceBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of EnhanceBertModel were not initialized from the model checkpoint at /root/autodl-tmp/MWP-BERT and are newly initialized: ['bert.embeddings.num_pos_embeddings.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'bert.embeddings.attribute_pos_embeddings.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertLMHeadModel were not initialized from the model checkpoint at /root/autodl-tmp/MWP-BERT and are newly initialized: ['bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The following encoder weights were not tied to the decoder ['bert/embeddings/attribute_pos_embeddings', 'bert/embeddings/num_pos_embeddings', 'bert/pooler']
epoch: 1
Total loss: 8.115752740929134
Tree loss: 0.9440334527964318
Seq2Seq loss: 7.171719287457423
training time 0h 5m 22s
--------------------------------
epoch: 2
Total loss: 1.7209686607212458
Tree loss: 0.6315723108380943
Seq2Seq loss: 1.0893963486226304
training time 0h 5m 19s
--------------------------------
epoch: 3
Total loss: 1.1031764888871471
Tree loss: 0.5063698024593091
Seq2Seq loss: 0.5968066865854033
training time 0h 5m 18s
--------------------------------
epoch: 4
Total loss: 0.8918093914711943
Tree loss: 0.4241143593570257
Seq2Seq loss: 0.4676950318215477
training time 0h 5m 20s
--------------------------------
epoch: 5
Total loss: 0.7140220990263804
Tree loss: 0.36206912593719104
Seq2Seq loss: 0.35195297286409627
training time 0h 5m 24s
--------------------------------
659 764 1000
test_answer_acc 0.659 0.764
testing time 0h 1m 32s
------------------------------------------------------
epoch: 6
Total loss: 0.5746045650132113
Tree loss: 0.31688399893144464
Seq2Seq loss: 0.25772056547401534
training time 0h 5m 24s
--------------------------------
epoch: 7
Total loss: 0.4846672777007714
Tree loss: 0.27880616569356975
Seq2Seq loss: 0.20586111252491568
training time 0h 5m 19s
--------------------------------
epoch: 8
Total loss: 0.41826700250367743
Tree loss: 0.24843421015674613
Seq2Seq loss: 0.16983279286464537
training time 0h 5m 24s
--------------------------------
epoch: 9
Total loss: 0.38449449382519796
Tree loss: 0.2353688164746383
Seq2Seq loss: 0.14912567714797587
training time 0h 5m 23s
--------------------------------
epoch: 10
Total loss: 0.33142792867929916
Tree loss: 0.20510573824726924
Seq2Seq loss: 0.12632219044328455
training time 0h 5m 26s
--------------------------------
700 813 1000
test_answer_acc 0.7 0.813
testing time 0h 1m 31s
------------------------------------------------------
epoch: 11
Total loss: 0.2979365506988818
Tree loss: 0.18834456220111637
Seq2Seq loss: 0.1095919877605856
training time 0h 5m 23s
--------------------------------
epoch: 12
Total loss: 0.2628731438242957
Tree loss: 0.16923842251615942
Seq2Seq loss: 0.09363472096486934
training time 0h 5m 28s
--------------------------------
epoch: 13
Total loss: 0.25648335712959036
Tree loss: 0.16111224912264557
Seq2Seq loss: 0.09537110804633611
training time 0h 5m 26s
--------------------------------
epoch: 14
Total loss: 0.2342266209220958
Tree loss: 0.14697981729619541
Seq2Seq loss: 0.08724680352179486
training time 0h 5m 28s
--------------------------------
epoch: 15
Total loss: 0.1990959193456209
Tree loss: 0.13004853654078846
Seq2Seq loss: 0.06904738317342234
training time 0h 5m 27s
--------------------------------
695 814 1000
test_answer_acc 0.695 0.814
testing time 0h 1m 38s
------------------------------------------------------
epoch: 16
Total loss: 0.17623494647083146
Tree loss: 0.11775461433798615
Seq2Seq loss: 0.058480332096267684
training time 0h 5m 28s
--------------------------------
epoch: 17
Total loss: 0.16528383642435074
Tree loss: 0.11121410992154092
Seq2Seq loss: 0.05406972675181903
training time 0h 5m 36s
--------------------------------
epoch: 18
Total loss: 0.15744988745770605
Tree loss: 0.1068978860546635
Seq2Seq loss: 0.05055200167315424
training time 0h 5m 28s
--------------------------------
epoch: 19
Total loss: 0.141197629931335
Tree loss: 0.09660655256428297
Seq2Seq loss: 0.04459107762450223
training time 0h 5m 41s
--------------------------------
epoch: 20
Total loss: 0.13241568853757893
Tree loss: 0.09268834057694521
Seq2Seq loss: 0.03972734796907471
training time 0h 5m 27s
--------------------------------
701 818 1000
test_answer_acc 0.701 0.818
testing time 0h 1m 33s
------------------------------------------------------
epoch: 21
Total loss: 0.11810666091987734
Tree loss: 0.08032901814908038
Seq2Seq loss: 0.03777764264629237
training time 0h 5m 29s
--------------------------------
epoch: 22
Total loss: 0.10619936439031426
Tree loss: 0.07121991918962504
Seq2Seq loss: 0.034979445211943856
training time 0h 5m 32s
--------------------------------
epoch: 23
Total loss: 0.09281518160480882
Tree loss: 0.062456437562426324
Seq2Seq loss: 0.03035874412538557
training time 0h 5m 27s
--------------------------------
epoch: 24
Total loss: 0.08805712863937966
Tree loss: 0.06049555501572822
Seq2Seq loss: 0.027561573622596317
training time 0h 5m 26s
--------------------------------
epoch: 25
Total loss: 0.08223513880986552
Tree loss: 0.056085531899298956
Seq2Seq loss: 0.026149606949430287
training time 0h 5m 33s
--------------------------------
721 839 1000
test_answer_acc 0.721 0.839
testing time 0h 1m 29s
------------------------------------------------------
epoch: 26
Total loss: 0.07716506965362728
Tree loss: 0.05326566694717955
Seq2Seq loss: 0.023899402784526888
training time 0h 5m 33s
--------------------------------
epoch: 27
Total loss: 0.07256509673154246
Tree loss: 0.050386342637485676
Seq2Seq loss: 0.022178754215747727
training time 0h 5m 40s
--------------------------------
epoch: 28
Total loss: 0.06963570034722277
Tree loss: 0.04837825419725934
Seq2Seq loss: 0.021257446259344587
training time 0h 5m 28s
--------------------------------
epoch: 29
Total loss: 0.06637356779045704
Tree loss: 0.0465824505158776
Seq2Seq loss: 0.019791117388884512
training time 0h 5m 33s
--------------------------------
epoch: 30
Total loss: 0.06177893359624862
Tree loss: 0.04337097229253152
Seq2Seq loss: 0.018407961234958206
training time 0h 5m 28s
--------------------------------
714 836 1000
test_answer_acc 0.714 0.836
testing time 0h 1m 31s
------------------------------------------------------
epoch: 31
Total loss: 0.059446351151783976
Tree loss: 0.04224339766453197
Seq2Seq loss: 0.017202953403193808
training time 0h 5m 25s
--------------------------------
epoch: 32
Total loss: 0.05431823317788744
Tree loss: 0.039061978562056926
Seq2Seq loss: 0.015256254611961723
training time 0h 5m 25s
--------------------------------
epoch: 33
Total loss: 0.04948585428187787
Tree loss: 0.03568810197750523
Seq2Seq loss: 0.013797752259002318
training time 0h 5m 24s
--------------------------------
epoch: 34
Total loss: 0.052300467461859665
Tree loss: 0.03802336482443703
Seq2Seq loss: 0.01427710262300261
training time 0h 5m 28s
--------------------------------
epoch: 35
Total loss: 0.0455451657762751
Tree loss: 0.03275451352571846
Seq2Seq loss: 0.012790652242906988
training time 0h 5m 24s
--------------------------------
719 839 1000
test_answer_acc 0.719 0.839
testing time 0h 1m 32s
------------------------------------------------------
epoch: 36
Total loss: 0.043630090348346556
Tree loss: 0.03174781142123778
Seq2Seq loss: 0.011882278774907176
training time 0h 5m 28s
--------------------------------
epoch: 37
Total loss: 0.044099276942718674
Tree loss: 0.032623250114104045
Seq2Seq loss: 0.011476026907573057
training time 0h 5m 27s
--------------------------------
epoch: 38
Total loss: 0.04156614028112935
Tree loss: 0.030971310408226725
Seq2Seq loss: 0.010594829782249907
training time 0h 5m 30s
--------------------------------
epoch: 39
Total loss: 0.03728148414298971
Tree loss: 0.027926214985683803
Seq2Seq loss: 0.00935526912512463
training time 0h 5m 31s
--------------------------------
epoch: 40
Total loss: 0.037625502527682986
Tree loss: 0.028529729351124886
Seq2Seq loss: 0.009095773221664638
training time 0h 5m 30s
--------------------------------
721 844 1000
test_answer_acc 0.721 0.844
testing time 0h 1m 30s
------------------------------------------------------
epoch: 41
Total loss: 0.0342161240822177
Tree loss: 0.02536051520610684
Seq2Seq loss: 0.00885560891040238
training time 0h 5m 30s
--------------------------------
epoch: 42
Total loss: 0.031106681365652006
Tree loss: 0.022874993373021933
Seq2Seq loss: 0.008231687967614847
training time 0h 5m 36s
--------------------------------
epoch: 43
Total loss: 0.02771248562550566
Tree loss: 0.02002876028210154
Seq2Seq loss: 0.007683725255740922
training time 0h 5m 29s
--------------------------------
epoch: 44
Total loss: 0.027206631500437135
Tree loss: 0.020110191099651318
Seq2Seq loss: 0.007096440381749626
training time 0h 5m 29s
--------------------------------
epoch: 45
Total loss: 0.02763275748113131
Tree loss: 0.02030836401846305
Seq2Seq loss: 0.007324393493047032
training time 0h 5m 30s
--------------------------------
726 856 1000
test_answer_acc 0.726 0.856
testing time 0h 1m 27s
------------------------------------------------------
epoch: 46
Total loss: 0.02729817735487764
Tree loss: 0.020427264382723673
Seq2Seq loss: 0.006870912999675111
training time 0h 5m 32s
--------------------------------
epoch: 47
Total loss: 0.023252222278497246
Tree loss: 0.01722167609973453
Seq2Seq loss: 0.006030546171244957
training time 0h 5m 36s
--------------------------------
epoch: 48
Total loss: 0.023422576468467807
Tree loss: 0.017414102730003354
Seq2Seq loss: 0.006008473735161696
training time 0h 5m 27s
--------------------------------
epoch: 49
Total loss: 0.02095694589169043
Tree loss: 0.015600137925601994
Seq2Seq loss: 0.005356807928367763
training time 0h 5m 32s
--------------------------------
epoch: 50
Total loss: 0.022402973118972516
Tree loss: 0.016927977651999517
Seq2Seq loss: 0.00547499547730442
training time 0h 5m 32s
--------------------------------
725 855 1000
test_answer_acc 0.725 0.855
testing time 0h 1m 35s
------------------------------------------------------
epoch: 51
Total loss: 0.020335989012600985
Tree loss: 0.015628733735102398
Seq2Seq loss: 0.004707255317890043
training time 0h 5m 37s
--------------------------------
epoch: 52
Total loss: 0.019483367869387074
Tree loss: 0.014741604580986032
Seq2Seq loss: 0.004741763267815138
training time 0h 5m 40s
--------------------------------
epoch: 53
Total loss: 0.01933380291735496
Tree loss: 0.014957551628205605
Seq2Seq loss: 0.00437625126816778
training time 0h 5m 33s
--------------------------------
epoch: 54
Total loss: 0.019599891521913784
Tree loss: 0.014932680766846812
Seq2Seq loss: 0.00466721076106799
training time 0h 5m 30s
--------------------------------
epoch: 55
Total loss: 0.01661049695590105
Tree loss: 0.012910046545046365
Seq2Seq loss: 0.0037004503995890403
training time 0h 5m 30s
--------------------------------
739 866 1000
test_answer_acc 0.739 0.866
testing time 0h 1m 32s
------------------------------------------------------
epoch: 56
Total loss: 0.01620115403933915
Tree loss: 0.012599885907789814
Seq2Seq loss: 0.0036012681101171336
training time 0h 5m 28s
--------------------------------
epoch: 57
Total loss: 0.01550299418835867
Tree loss: 0.011967066125045642
Seq2Seq loss: 0.0035359280590046044
training time 0h 5m 26s
--------------------------------
epoch: 58
Total loss: 0.015124775210534028
Tree loss: 0.011823676160594387
Seq2Seq loss: 0.003301099021786522
training time 0h 5m 36s
--------------------------------
epoch: 59
Total loss: 0.01414774847252075
Tree loss: 0.0111904144922162
Seq2Seq loss: 0.002957334000373884
training time 0h 5m 43s
--------------------------------
epoch: 60
Total loss: 0.014940862940365675
Tree loss: 0.011008222967053354
Seq2Seq loss: 0.0039326400110110135
training time 0h 5m 28s
--------------------------------
736 856 1000
test_answer_acc 0.736 0.856
testing time 0h 1m 33s
------------------------------------------------------
epoch: 61
Total loss: 0.013413600008822189
Tree loss: 0.010460498967071945
Seq2Seq loss: 0.0029531010561592783
training time 0h 5m 30s
--------------------------------
epoch: 62
Total loss: 0.012379761400555273
Tree loss: 0.009591218197857935
Seq2Seq loss: 0.0027885432222858205
training time 0h 5m 32s
--------------------------------
epoch: 63
Total loss: 0.01186978772912685
Tree loss: 0.00902319946406109
Seq2Seq loss: 0.0028465882808761302
training time 0h 5m 41s
--------------------------------
epoch: 64
Total loss: 0.011425232042263408
Tree loss: 0.008616946855617933
Seq2Seq loss: 0.0028082851860684547
training time 0h 5m 34s
--------------------------------
epoch: 65
Total loss: 0.010691614520315395
Tree loss: 0.008385468943237455
Seq2Seq loss: 0.0023061455817490616
training time 0h 5m 24s
--------------------------------
740 857 1000
test_answer_acc 0.74 0.857
testing time 0h 1m 31s
------------------------------------------------------
epoch: 66
Total loss: 0.010018870250250353
Tree loss: 0.007930584904408748
Seq2Seq loss: 0.002088285340571481
training time 0h 5m 30s
--------------------------------
epoch: 67
Total loss: 0.00986443754325405
Tree loss: 0.007922682823076756
Seq2Seq loss: 0.0019417547474511435
training time 0h 5m 26s
--------------------------------
epoch: 68
Total loss: 0.010028480500875469
Tree loss: 0.0076042658175920165
Seq2Seq loss: 0.002424214645331969
training time 0h 5m 26s
--------------------------------
epoch: 69
Total loss: 0.009398765394766076
Tree loss: 0.007368179231760229
Seq2Seq loss: 0.0020305861625524745
training time 0h 5m 27s
--------------------------------
epoch: 70
Total loss: 0.0085194937566424
Tree loss: 0.006848930848999004
Seq2Seq loss: 0.001670562898993578
training time 0h 5m 29s
--------------------------------
742 862 1000
test_answer_acc 0.742 0.862
testing time 0h 1m 31s
------------------------------------------------------
epoch: 71
Total loss: 0.008320716679217736
Tree loss: 0.006769277734821636
Seq2Seq loss: 0.0015514389353464915
training time 0h 5m 25s
--------------------------------
epoch: 72
Total loss: 0.007820268172552767
Tree loss: 0.006316655134691894
Seq2Seq loss: 0.0015036130301892445
training time 0h 5m 31s
--------------------------------
epoch: 73
Total loss: 0.007883636959206968
Tree loss: 0.006440282248100284
Seq2Seq loss: 0.00144335470713898
training time 0h 5m 30s
--------------------------------
epoch: 74
Total loss: 0.006874568793389649
Tree loss: 0.005634665576123589
Seq2Seq loss: 0.001239903223574822
training time 0h 5m 28s
--------------------------------
epoch: 75
Total loss: 0.006661080947281931
Tree loss: 0.0053706816747034645
Seq2Seq loss: 0.0012903992691651136
training time 0h 5m 25s
--------------------------------
733 855 1000
test_answer_acc 0.733 0.855
testing time 0h 1m 30s
------------------------------------------------------
epoch: 76
Total loss: 0.006573249672358754
Tree loss: 0.005466906728848105
Seq2Seq loss: 0.0011063429399633452
training time 0h 5m 31s
--------------------------------
734 855 1000
test_answer_acc 0.734 0.855
testing time 0h 1m 31s
------------------------------------------------------
epoch: 77
Total loss: 0.006417242840893572
Tree loss: 0.005295587498155226
Seq2Seq loss: 0.0011216553614791568
training time 0h 5m 37s
--------------------------------
732 855 1000
test_answer_acc 0.732 0.855
testing time 0h 1m 34s
------------------------------------------------------
epoch: 78
Total loss: 0.006341760345907696
Tree loss: 0.0052920823902345366
Seq2Seq loss: 0.0010496779821151379
training time 0h 5m 30s
--------------------------------
728 854 1000
test_answer_acc 0.728 0.854
testing time 0h 1m 33s
------------------------------------------------------
epoch: 79
Total loss: 0.006443614098217257
Tree loss: 0.0054372458311225
Seq2Seq loss: 0.001006368270533526
training time 0h 5m 33s
--------------------------------
729 855 1000
test_answer_acc 0.729 0.855
testing time 0h 1m 31s
------------------------------------------------------
epoch: 80
Total loss: 0.005746940530904857
Tree loss: 0.00472982137064106
Seq2Seq loss: 0.0010171191550012307
training time 0h 5m 29s
--------------------------------
732 859 1000
test_answer_acc 0.732 0.859
testing time 0h 1m 32s
------------------------------------------------------
